{
 "cells": [
  {
   "cell_type": "raw",
   "id": "88155dd0-f777-465b-a3ab-9d5cee1a21f4",
   "metadata": {},
   "source": [
    "Vector stores are data structures or databases designed to store and manage high-dimensional vectors efficiently. They enable efficient similarity search, nearest neighbor search, and other vector-related operations. Vector stores can be built using various data structures such as approximate nearest neighbor (ANN) techniques, KD trees, or Vantage Point trees."
   ]
  },
  {
   "cell_type": "raw",
   "id": "1909d88f-e25c-4c70-9990-a2aa2785cf53",
   "metadata": {},
   "source": [
    "Deep Lake, serves as both a data lake for deep learning and a multi-modal vector store. As a multi-modal vector store, it allows users to store images, audio, videos, text, and metadata in a format optimized for deep learning. It enables hybrid search, allowing users to search both embeddings and their attributes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d98fd7-a429-408c-9c6c-3e11d75cfdd6",
   "metadata": {},
   "source": [
    "Creating Deep Lake Vector Store embeddings example\n",
    "Deep Lake provides well-written documentation, and besides other examples for which they added Jupyter Notebooks, we can follow the one for vector store creation.\n",
    "\n",
    "This task aims to leverage the power of NLP technologies, particularly OpenAI and Deep Lake, to generate and manipulate high-dimensional embeddings. These embeddings can be used for a variety of purposes, such as searching for relevant documents, moderating content, and answering questions. In this case, we will create a Deep Lake database for a retrieval-based question-answering system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38a98b8a-7284-4a6e-9e35-417de65b4edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, dotenv_values\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "config = dotenv_values(\"C:/Users/SACHENDRA/Documents/Activeloop/.env\")\n",
    "load_dotenv(\"C:/Users/SACHENDRA/Documents/Activeloop/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb7ee058-5ab1-43c1-91f3-18108e7c06ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de6dd554-d967-4c95-a377-f33840ca70f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We then create some documents using the RecursiveCharacterTextSplitter class.\n",
    "\n",
    "# create our documents\n",
    "texts = [\n",
    "    \"Napoleon Bonaparte was born in 15 August 1769\",\n",
    "    \"Louis XIV was born in 5 September 1638\",\n",
    "    \"Lady Gaga was born in 28 March 1986\",\n",
    "    \"Michael Jeffrey Jordan was born in 17 February 1963\"\n",
    "]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.create_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74f57e30-0c81-4006-a91e-cf7d644ba3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SACHENDRA\\miniconda3\\envs\\activeloop2\\Lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (3.9.3) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n",
      "The dataset is private so make sure you are logged in!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/sachendra/langchain_course_embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://sachendra/langchain_course_embeddings loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ingest: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:39<00:00\n",
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://sachendra/langchain_course_embeddings', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype     shape     dtype  compression\n",
      "  -------   -------   -------   -------  ------- \n",
      " embedding  generic  (4, 1536)  float32   None   \n",
      "    ids      text     (4, 1)      str     None   \n",
      " metadata    json     (4, 1)      str     None   \n",
      "   text      text     (4, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['c20194fd-0a0e-11ef-8b8f-a841f4293306',\n",
       " 'c20194fe-0a0e-11ef-8ad8-a841f4293306',\n",
       " 'c20194ff-0a0e-11ef-bfd3-a841f4293306',\n",
       " 'c2019500-0a0e-11ef-8204-a841f4293306']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The next step is to create a Deep Lake database and load our documents into it.\n",
    "\n",
    "# initialize embeddings model\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# create Deep Lake dataset\n",
    "# TODO: use your organization id here. (by default, org id is your username)\n",
    "my_activeloop_org_id = \"sachendra\"\n",
    "my_activeloop_dataset_name = \"langchain_course_embeddings\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n",
    "\n",
    "# add documents to our Deep Lake dataset\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f267f9f-8b64-4f8f-9754-50217960d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now create a retriever from the database.\n",
    "\n",
    "# create retriever from db\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95002a96-95e8-4923-a7b2-514b17580b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Michael Jordan was born on 17 February 1963.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# istantiate the llm wrapper\n",
    "model = ChatOpenAI(model='gpt-3.5-turbo')\n",
    "\n",
    "# create the question-answering chain\n",
    "qa_chain = RetrievalQA.from_llm(model, retriever=retriever)\n",
    "\n",
    "# ask a question to the chain\n",
    "qa_chain.run(\"When was Michael Jordan born?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35dfdad-5c5c-42cd-9e71-f7cf4b4cd7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
