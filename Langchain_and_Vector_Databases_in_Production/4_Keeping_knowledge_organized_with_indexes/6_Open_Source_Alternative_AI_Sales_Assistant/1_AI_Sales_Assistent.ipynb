{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab3c296a-bd30-4cd0-b4b8-4ec8c2a910b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, dotenv_values\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "config = dotenv_values(\"C:/Users/SACHENDRA/Documents/Activeloop/.env\")\n",
    "load_dotenv(\"C:/Users/SACHENDRA/Documents/Activeloop/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91323549-9574-4fd7-82e3-da6e3c6d819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "class DeepLakeLoader:\n",
    "    def __init__(self, source_data_path):\n",
    "        self.source_data_path = source_data_path\n",
    "        self.file_name = os.path.basename(source_data_path) # What we'll name our database \n",
    "        self.data = self.split_data()\n",
    "        if False:\n",
    "            self.db = self.load_db()\n",
    "        else:\n",
    "            self.db = self.create_db()\n",
    "    def split_data(self):  \n",
    "        \"\"\"  \n",
    "        Preprocess the data by splitting it into passages.  \n",
    "    \n",
    "        If using a different data source, this function will need to be modified.  \n",
    "    \n",
    "        Returns:  \n",
    "            split_data (list): List of passages.  \n",
    "        \"\"\"  \n",
    "        with open(self.source_data_path, 'r') as f:  \n",
    "            content = f.read()  \n",
    "        split_data = re.split(r'(?=\\d+\\. )', content)\n",
    "        if split_data[0] == '':  \n",
    "            split_data.pop(0)  \n",
    "        split_data = [entry for entry in split_data if len(entry) >= 30]  \n",
    "        return split_data\n",
    "\n",
    "# Their is a method that Splits data called split_data()\n",
    "# Since we know the structure of our knowledge base, we use this method to split it into individual entries, \n",
    "# each representing an example of a customer objection. When we run our similarity search using the detected customer objection.\n",
    "\n",
    "# After preprocessing the data, we check if we’ve already created a database for this data.\n",
    "# One of the great things about Deep Lake is that it provides us with persistent storage, so we only need to create the database once.\n",
    "# If you restart the app, the database doesn’t disappear!\n",
    "\n",
    "# Creating and loading the database is super easy: \n",
    "\n",
    "    def load_db(self):  \n",
    "        \"\"\"  \n",
    "        Load the database if it already exists.  \n",
    "    \n",
    "        Returns:  \n",
    "            DeepLake: DeepLake object.  \n",
    "        \"\"\"  \n",
    "        return DeepLake(dataset_path=f'deeplake/{self.file_name}', embedding_function=OpenAIEmbeddings(), read_only=True)  \n",
    "\n",
    "    def create_db(self):  \n",
    "        \"\"\"  \n",
    "        Create the database if it does not already exist.  \n",
    "    \n",
    "        Databases are stored in the deeplake directory.  \n",
    "    \n",
    "        Returns:  \n",
    "            DeepLake: DeepLake object.  \n",
    "        \"\"\"  \n",
    "        return DeepLake.from_texts(self.data, OpenAIEmbeddings(), dataset_path=f'deeplake/{self.file_name}')\n",
    "\n",
    "    def query_db(self, query):  \n",
    "        \"\"\"  \n",
    "        Query the database for passages that are similar to the query.  \n",
    "    \n",
    "        Args:  \n",
    "            query (str): Query string.  \n",
    "    \n",
    "        Returns:  \n",
    "            content (list): List of passages that are similar to the query.  \n",
    "        \"\"\"  \n",
    "        results = self.db.similarity_search(query, k=3)  \n",
    "        content = []  \n",
    "        for result in results:  \n",
    "            content.append(result.page_content)  \n",
    "        return content\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c9915-04aa-4aa4-93b6-d38d546ec895",
   "metadata": {},
   "source": [
    "Just like that, our knowledge base becomes a vector database that we can now query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42e74f6-1c6d-4ba6-ac99-7ce5aaa5b916",
   "metadata": {},
   "source": [
    "We don’t want the metadata to be passed to the LLM, so we take the results of our similarity search and pull just the content from them. And that’s it! We now have our custom knowledge base stored in a Deep Lake vector database and ready to be queried!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e62dbc2-c012-43f4-ad09-3d0aa9b10add",
   "metadata": {},
   "source": [
    "Connecting Our Database to GPT-4\n",
    "Now, all we need to do is connect our LLM to the database. First, we need to create a DeepLakeLoader instance with the path to our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2450fe89-307f-4195-becc-70b7d8af4840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplake/salestesting.txt loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SACHENDRA\\miniconda3\\envs\\activeloop2\\Lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (3.9.3) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n",
      "Evaluating ingest: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='deeplake/salestesting.txt', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype     shape     dtype  compression\n",
      "  -------   -------   -------   -------  ------- \n",
      " embedding  generic  (1, 1536)  float32   None   \n",
      "    ids      text     (1, 1)      str     None   \n",
      " metadata    json     (1, 1)      str     None   \n",
      "   text      text     (1, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "db = DeepLakeLoader(\"salestesting.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7e8c90d-8417-4272-b511-5a7afd1eb398",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Objection: \"There's no money.\"\n",
    "It could be that your prospect's business simply isn't big enough or generating enough cash right now to afford a product like yours. Track their growth and see how you can help your prospect get to a place where your offering would fit into their business.\n",
    "\n",
    "Objection: \"We don't have any budget left this year.\"\n",
    "A variation of the \"no money\" objection, what your prospect's telling you here is that they're having cash flow issues. But if there's a pressing problem, it needs to get solved eventually. Either help your prospect secure a budget from executives to buy now or arrange a follow-up call for when they expect funding to return.\n",
    "\n",
    "Objection: \"We need to use that budget somewhere else.\"\n",
    "Prospects sometimes try to earmark resources for other uses. It's your job to make your product/service a priority that deserves budget allocation now. Share case studies of similar companies that have saved money, increased efficiency, or had a massive ROI with you.\n",
    "\"\"\"\n",
    "\n",
    "# Split the text into a list using the keyword \"Objection: \"\n",
    "objections_list = text.split(\"Objection: \")[1:]  # We ignore the first split as it is empty\n",
    "\n",
    "# Now, prepend \"Objection: \" to each item as splitting removed it\n",
    "objections_list = [\"Objection: \" + objection for objection in objections_list]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f039265c-f12c-4f75-a567-83635870c6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_objection = \"We need to use that budget somewhere else\"\n",
    "\n",
    "results = db.query_db(detected_objection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e434b2d9-e32c-4373-a467-bb03b5f7d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "system_message = SystemMessage(content= \"\"\"Reminder: You're SalesCopilot.Your goal is to help the user in their sales call with the customer. \n",
    "Using conversation transcripts, you'll help create responses and guide the user (labeled You).\n",
    "Keep your responses helpful, concise, and relevant to the conversation.  \n",
    "The transcripts may be fragmented, incomplete, or even incorrect. Do not ask for clarification, do your best to understand what\n",
    "the transcripts say based on context. Be sure of everything you say.\n",
    "Keep responses concise and to the point. Starting now, answer the user's question based on the transcript:\"\"\")\n",
    "\n",
    "human_message = HumanMessage(content=f'Customer objection: {detected_objection} | Relevant guidelines: {results}')\n",
    "\n",
    "response = chat([system_message, human_message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9306aba-660d-43be-bdb8-313f75d3ed93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response to customer objection: \"We need to use that budget somewhere else\": \n",
      "Acknowledge the customer's perspective and emphasize the value and benefits your product/service can bring to their business. Share relevant case studies of companies that have achieved cost savings, increased efficiency, or significant ROI by using your offering. Show how prioritizing your solution now can lead to long-term benefits for their business.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1e809e-5cfb-420e-a896-1bc06317e90d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
