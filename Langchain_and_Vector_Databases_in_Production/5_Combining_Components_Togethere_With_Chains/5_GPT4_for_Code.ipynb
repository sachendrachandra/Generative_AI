{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d354ccd0-1c84-40c1-9ccd-17f2c7f28b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, dotenv_values\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "config = dotenv_values(\"C:/Users/SACHENDRA/Documents/Activeloop/.env\")\n",
    "load_dotenv(\"C:/Users/SACHENDRA/Documents/Activeloop/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc614d52-33c6-4577-a0ae-3a0ac1c76a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "# os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')\n",
    "# os.environ['ACTIVELOOP_TOKEN'] = getpass.getpass('Activeloop Token:')\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58ace646-50a4-4efa-87f9-47ca4ca01fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedding function is deprecated and will be removed in the future. Please use embedding instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://davitbun/twitter-algorithm already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "db = DeepLake(dataset_path=\"hub://davitbun/twitter-algorithm\", read_only=True, embedding_function=embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "142c7d58-90e9-4733-ba39-9c67dda9d10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()\n",
    "retriever.search_kwargs['distance_metric'] = 'cos'\n",
    "retriever.search_kwargs['fetch_k'] = 100\n",
    "retriever.search_kwargs['k'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "570008a3-1e86-4122-800f-246259fe9579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(x):\n",
    "    if 'com.google' in x['text'].data()['value']:\n",
    "        return False\n",
    "    metadata = x['metadata'].data()['value']\n",
    "    return 'scala' in metadata['source'] or 'py' in metadata['source']\n",
    "\n",
    "# Uncomment the following line to apply custom filtering\n",
    "# retriever.search_kwargs['filter'] = filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb9299a5-b6ce-4c02-a81c-20c01e32642b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SACHENDRA\\miniconda3\\envs\\activeloop2\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "model = ChatOpenAI(model='gpt-3.5-turbo') # switch to 'gpt-4'\n",
    "qa = ConversationalRetrievalChain.from_llm(model,retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "243c59f7-b506-49aa-95ee-23057578cd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> **Question**: What does favCountParams do? \n",
      "\n",
      "**Answer**: The `favCountParams` is a parameter of type `ThriftLinearFeatureRankingParams` that likely relates to favorited counts of tweets in a ranking or scoring system. It is used to rank or score tweets based on the number of favorites they have received. \n",
      "\n",
      "-> **Question**: is it Likes + Bookmarks, or not clear from the code? \n",
      "\n",
      "**Answer**: Based on the provided code snippets and context, it seems that `favCountParams` specifically refers to the count of favorites (likes) on tweets. There is no mention of bookmarks in the context provided. \n",
      "\n",
      "-> **Question**: What are the major negative modifiers that lower your linear ranking parameters? \n",
      "\n",
      "**Answer**: The major negative modifiers that lower the linear ranking parameters are:\n",
      "\n",
      "1. Social Filter\n",
      "2. Direct Follow Boost\n",
      "3. Trusted Circle Boost\n",
      "4. Out of Network Reply Penalty\n",
      "5. No Text Hit Demotion\n",
      "6. URL Only Hit Demotion\n",
      "7. Name Only Hit Demotion\n",
      "8. Separate Text and Name Hit Demotion\n",
      "9. Separate Text and URL Hit Demotion\n",
      "\n",
      "These modifiers can contribute to lowering the linear ranking parameters in the scoring process. \n",
      "\n",
      "-> **Question**: How do you get assigned to SimClusters? \n",
      "\n",
      "**Answer**: Based on the provided context, it seems that getting assigned to SimClusters involves generating cluster assignments based on user interactions with content. The process involves building user and tweet embeddings based on inferred communities to support recommendation tasks. To get assigned to SimClusters, users likely need to interact with content in a way that allows the system to create sparse, interpretable vectors representing their preferences or behaviors within the community structure. The exact criteria and mechanisms for assignment to SimClusters may be further detailed in the documentation or code related to the SimClusters algorithm and implementation. \n",
      "\n",
      "-> **Question**: What is needed to migrate from one SimClusters to another SimClusters? \n",
      "\n",
      "**Answer**: To migrate from one SimClusters to another SimClusters, you would typically need to follow a process similar to the following:\n",
      "\n",
      "1. Understand the differences between the two versions of SimClusters, such as any changes in algorithms, data structures, or APIs.\n",
      "2. Prepare your data for migration, ensuring compatibility with the new version.\n",
      "3. Update your codebase and configurations to align with the new version of SimClusters.\n",
      "4. Test the migration thoroughly to ensure that the new SimClusters setup functions correctly and provides the expected results.\n",
      "5. Monitor the performance and behavior of the new SimClusters to address any issues that may arise during or after migration.\n",
      "\n",
      "This general process may need to be adapted based on the specific differences between the two versions of SimClusters you are migrating between. \n",
      "\n",
      "-> **Question**: How much do I get boosted within my cluster? \n",
      "\n",
      "**Answer**: I don't have enough information to determine the exact boost within your cluster based on the provided context. \n",
      "\n",
      "-> **Question**: How does Heavy ranker work. what are it’s main inputs? \n",
      "\n",
      "**Answer**: The main inputs of the Heavy ranker include the scoring algorithm, source embedding ID, candidate embedding type, minimum score, and a sequence of tweet candidates. The Heavy ranker works by taking these inputs and then ranking the tweet candidates based on the scoring algorithm provided. The ranking process involves fetching candidate embeddings, constructing DataRecords for user-candidate pairs, sending these pairs to an ML prediction service for scoring, and then returning a prediction score representing the likelihood of user engagement with the candidate. The ranking decision is based on a weighted sum of probabilities related to user follow and positive engagement with the candidate. \n",
      "\n",
      "-> **Question**: How can one influence Heavy ranker? \n",
      "\n",
      "**Answer**: To influence the Heavy ranker algorithm, you would typically need to adjust the features used in the ranking process, as well as potentially the weights assigned to each feature. In the context provided, the Heavy ranker algorithm is designed to rank candidates based on various factors such as scoring algorithms, candidate embeddings, and minimum score thresholds.\n",
      "\n",
      "Some ways you might influence the Heavy ranker algorithm include:\n",
      "1. **Adjusting Scoring Algorithm**: You could modify the scoring algorithm used by the Heavy ranker to prioritize certain engagement metrics over others.\n",
      "2. **Customizing Embedding Types**: By changing the candidate embedding types or source embedding IDs, you can alter how similarities are calculated between users and candidates.\n",
      "3. **Tuning Minimum Score Threshold**: You can adjust the minimum score threshold parameter to filter out candidates below a certain engagement level.\n",
      "4. **Modifying Features**: Changing the features used for ranking, such as incorporating additional user-candidate relationship metrics or engagement predictors.\n",
      "5. **Fine-tuning Weights**: Adjusting the weights assigned to different features to emphasize or de-emphasize their importance in the ranking process.\n",
      "\n",
      "Ultimately, influencing the Heavy ranker algorithm involves understanding the existing features, scoring mechanisms, and parameters, and then making informed adjustments to tailor the ranking outcomes to specific objectives or user behaviors. \n",
      "\n",
      "-> **Question**: why threads and long tweets do so well on the platform? \n",
      "\n",
      "**Answer**: Threads and long tweets can perform well on the platform for several reasons:\n",
      "\n",
      "1. **Engagement**: Threads and long tweets can encourage more engagement from users. When users are interested in a topic and see a long tweet or a thread, they may spend more time reading through the content, liking, retweeting, or replying to it. This increased engagement can boost the visibility and reach of the tweets.\n",
      "\n",
      "2. **Depth of Content**: Long tweets and threads allow users to provide more detailed and in-depth information on a topic. This can be valuable for sharing complex ideas, telling a story, providing context, or expressing opinions in a more nuanced way. Users who appreciate detailed content may find long tweets and threads more engaging.\n",
      "\n",
      "3. **Storytelling**: Threads are often used to tell a story or present information in a structured manner. This storytelling format can captivate users and keep them interested in following along with each tweet in the thread. It can create a sense of anticipation and engagement as users progress through the thread.\n",
      "\n",
      "4. **Context and Continuity**: Threads can help maintain context and continuity in a conversation or a series of related tweets. By organizing content into a thread, users can easily follow the progression of thoughts or ideas without losing track of the context. This can enhance the overall user experience and make it easier for users to consume the content.\n",
      "\n",
      "5. **Algorithmic Considerations**: Twitter's algorithms may also take into account the engagement and interaction with threads and long tweets when determining which content to surface to users. If threads and long tweets consistently receive positive engagement signals, they may be more likely to be shown to a wider audience, leading to increased visibility and reach.\n",
      "\n",
      "Overall, the format of threads and long tweets provides users with more opportunities to engage with detailed content, storytelling, and context, which can contribute to their performance on the platform. \n",
      "\n",
      "-> **Question**: Are thread and long tweet creators building a following that reacts to only threads? \n",
      "\n",
      "**Answer**: Based on the provided context about Twitter's Tweet Search System (Earlybird) and the architecture of indexing tweets into clusters, there is no specific mention of a feature or mechanism that tailors the following tab based on users who react only to threads or long tweets. \n",
      "\n",
      "Therefore, based on the information available, it is not clear whether thread and long tweet creators are building a following that reacts only to threads. \n",
      "\n",
      "-> **Question**: Do you need to follow different strategies to get most followers vs to get most likes and bookmarks per tweet? \n",
      "\n",
      "**Answer**: To get the most followers on Twitter, users typically focus on creating engaging content, interacting with their followers, using hashtags effectively, and posting consistently. On the other hand, to get the most likes and bookmarks per tweet, users often prioritize high-quality content, visuals, timing of posts, and engaging with trending topics. While there may be some overlap in strategies, the emphasis may differ based on the specific goal of gaining followers versus maximizing engagement on individual tweets. \n",
      "\n",
      "-> **Question**: Content meta data and how it impacts virality (e.g. ALT in images). \n",
      "\n",
      "**Answer**: I don't have that specific information on how content meta data, like ALT text in images, impacts virality on social media platforms like Twitter. \n",
      "\n",
      "-> **Question**: What are some unexpected fingerprints for spam factors? \n",
      "\n",
      "**Answer**: Some unexpected fingerprints for spam factors could include:\n",
      "1. Presence of non-media non-news links in the content.\n",
      "2. Low user reputation score (tweepcred) below a certain threshold.\n",
      "3. Lack of engagement metrics like retweets, replies, and favorites on a tweet.\n",
      "4. Skipping content due to social filters.\n",
      "5. Applying boosts or penalties based on direct follows, trusted circle relationships, or out-of-network interactions. \n",
      "\n",
      "-> **Question**: Is there any difference between company verified checkmarks and blue verified individual checkmarks? \n",
      "\n",
      "**Answer**: In the context provided, \"company verified checkmarks\" refer to accounts that have been verified by a platform as belonging to a legitimate company or organization. On the other hand, \"blue verified individual checkmarks\" likely refer to accounts that have been verified as genuine individuals, possibly with a blue checkmark badge indicating their authenticity. The distinction lies in the type of entity being verified: companies or individuals. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"What does favCountParams do?\",\n",
    "    \"is it Likes + Bookmarks, or not clear from the code?\",\n",
    "    \"What are the major negative modifiers that lower your linear ranking parameters?\",   \n",
    "    \"How do you get assigned to SimClusters?\",\n",
    "    \"What is needed to migrate from one SimClusters to another SimClusters?\",\n",
    "    \"How much do I get boosted within my cluster?\",   \n",
    "    \"How does Heavy ranker work. what are it’s main inputs?\",\n",
    "    \"How can one influence Heavy ranker?\",\n",
    "    \"why threads and long tweets do so well on the platform?\",\n",
    "    \"Are thread and long tweet creators building a following that reacts to only threads?\",\n",
    "    \"Do you need to follow different strategies to get most followers vs to get most likes and bookmarks per tweet?\",\n",
    "    \"Content meta data and how it impacts virality (e.g. ALT in images).\",\n",
    "    \"What are some unexpected fingerprints for spam factors?\",\n",
    "    \"Is there any difference between company verified checkmarks and blue verified individual checkmarks?\",\n",
    "] \n",
    "chat_history = []\n",
    "\n",
    "for question in questions:  \n",
    "    result = qa.invoke({\"question\": question, \"chat_history\": chat_history})\n",
    "    chat_history.append((question, result['answer']))\n",
    "    print(f\"-> **Question**: {question} \\n\")\n",
    "    print(f\"**Answer**: {result['answer']} \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764e5af4-5186-43d9-a767-3850fc6be848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
