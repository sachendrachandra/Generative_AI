{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79604c68-7ea8-4d41-a937-24ddeca92495",
   "metadata": {},
   "source": [
    "Depending on the application, memory is the next component that will complete a chain. LangChain provides a ConversationalChain to track previous prompts and responses using the ConversationalBufferMemory class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87c8520f-0ef6-4d92-8cc1-5ba267d17ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, dotenv_values\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "config = dotenv_values(\"C:/Users/SACHENDRA/Documents/Activeloop/.env\")\n",
    "load_dotenv(\"C:/Users/SACHENDRA/Documents/Activeloop/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec8a887f-8706-4386-ac77-e4193d10453a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SACHENDRA\\miniconda3\\envs\\activeloop2\\Lib\\site-packages\\langchain\\llms\\openai.py:165: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "C:\\Users\\SACHENDRA\\miniconda3\\envs\\activeloop2\\Lib\\site-packages\\langchain\\llms\\openai.py:677: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain import PromptTemplate, OpenAI, LLMChain\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "template = \"\"\"List all possible words as substitute for 'artificial' as comma separated.\"\"\"\n",
    "\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63f47ae5-7a49-4c3a-a2ea-5583a939098b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'synthetic, simulated, man-made, fake, imitation'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationBufferMemory()\n",
    ")\n",
    "\n",
    "conversation.predict(input=\"List all possible words as substitute for 'artificial' as comma separated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc866bdf-849e-4699-a8b5-b008db652b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'replica, faux, counterfeit, ersatz'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, we can ask it to return the following four replacement words. \n",
    "# It uses the memory to find the next options.\n",
    "\n",
    "conversation.predict(input=\"And the next 4?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c6b3ce-4eca-4b20-a1a0-111d6c31e8d4",
   "metadata": {},
   "source": [
    "SEQUENTIAL CHAINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6313bccb-98f2-4a69-a511-e8beebe49c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poet\n",
    "poet_template: str = \"\"\"You are an American poet, your job is to come up with\\\n",
    "poems based on a given theme.\n",
    "\n",
    "Here is the theme you have been asked to generate a poem on:\n",
    "{input}\\\n",
    "\"\"\"\n",
    "\n",
    "poet_prompt_template: PromptTemplate = PromptTemplate(\n",
    "    input_variables=[\"input\"], template=poet_template)\n",
    "\n",
    "# creating the poet chain\n",
    "poet_chain: LLMChain = LLMChain(\n",
    "    llm=llm, output_key=\"poem\", prompt=poet_prompt_template)\n",
    "\n",
    "# critic\n",
    "critic_template: str = \"\"\"You are a critic of poems, you are tasked\\\n",
    "to inspect the themes of poems. Identify whether the poem includes romantic expressions or descriptions of nature.\n",
    "\n",
    "Your response should be in the following format, as a Python Dictionary.\n",
    "poem: this should be the poem you received \n",
    "Romantic_expressions: True or False\n",
    "Nature_descriptions: True or False\n",
    "\n",
    "Here is the poem submitted to you:\n",
    "{poem}\\\n",
    "\"\"\"\n",
    "\n",
    "critic_prompt_template: PromptTemplate = PromptTemplate(\n",
    "    input_variables=[\"poem\"], template=critic_template)\n",
    "\n",
    "# creating the critic chain\n",
    "critic_chain: LLMChain = LLMChain(\n",
    "    llm=llm, output_key=\"critic_verified\", prompt=critic_prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5a4ce5-88d8-4f9d-bfca-bd360a55c381",
   "metadata": {},
   "source": [
    "In this example we define two processes in a chain: one for generating poems based on a given theme (\"poet\") and another for evaluating these poems on their romantic and natural elements (\"critic\"). The poet process uses a template to instruct an AI model to create poems, while the critic process analyzes these poems, flagging them for specific content. The setup utilizes prompt templates and chains to seamlessly integrate content generation with content verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "331bebdf-19f4-4cb9-b3ea-202da323322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[poet_chain, critic_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3eba3be-77ad-4a52-90f0-f20f31b20eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"poem\": \"In the quiet of the morning light,\\nNature's beauty shines so bright.\\nThe sun rises over the horizon,\\nPainting the sky with colors so fine.\\n\\nThe trees sway in the gentle breeze,\\nTheir leaves rustling with such ease.\\nBirds sing their sweet melodies,\\nAs they flit and flutter through the trees.\\n\\nThe flowers bloom in vibrant hues,\\nTheir petals kissed by morning dew.\\nButterflies dance in the air,\\nTheir delicate wings so fair.\\n\\nThe mountains stand tall and proud,\\nTheir peaks reaching up to the clouds.\\nRivers flow with a soothing sound,\\nTheir waters clear and profound.\\n\\nNature's beauty is a sight to behold,\\nA treasure more valuable than gold.\\nIn every leaf and every flower,\\nWe find peace and solace in nature's power.\",\n",
      "\"Romantic_expressions\": False,\n",
      "\"Nature_descriptions\": True\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Run the poet and critic chain with a specific theme\n",
    "theme: str = \"the beauty of nature\"\n",
    "review = overall_chain.run(theme)\n",
    "\n",
    "# Print the review to see the critic's evaluation\n",
    "print(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45890770-86a5-4b3b-ad73-8b15338cfd79",
   "metadata": {},
   "source": [
    "Debug:\n",
    "\n",
    "It is possible to trace the inner workings of any chain by setting the verbose argument to True. As you can see in the following code, the chain will return the initial prompt and the output. The output depends on the application. It may contain more information if there are more steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c4155c4-23dd-4cab-8880-c35510e5a400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mList all possible words as substitute for 'artificial' as comma separated.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'synthetic, man-made, fake, imitation, simulated, faux, fabricated, counterfeit, ersatz, pseudo'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"List all possible words as substitute for 'artificial' as comma separated.\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "\n",
    "{input}\"\"\"\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate(template=template, input_variables=[\"history\", \"input\"], output_parser=output_parser),\n",
    "    memory=ConversationBufferMemory(),\n",
    "    verbose=True)\n",
    "\n",
    "conversation.predict(input=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba4039c-ff28-4fab-b84d-f5af285247ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
