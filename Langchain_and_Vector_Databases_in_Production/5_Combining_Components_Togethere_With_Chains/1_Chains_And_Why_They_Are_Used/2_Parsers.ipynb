{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faece565-8d8a-49f5-9934-52ddb03b5d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, dotenv_values\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "config = dotenv_values(\"C:/Users/SACHENDRA/Documents/Activeloop/.env\")\n",
    "load_dotenv(\"C:/Users/SACHENDRA/Documents/Activeloop/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a4583e-3461-4bb0-9e77-f8d771e71572",
   "metadata": {},
   "source": [
    "the output parsers can define a data schema to generate correctly formatted responses. It wouldnâ€™t be an end-to-end pipeline without using parsers to extract information from the LLM textual output. The following example shows the use of CommaSeparatedListOutputParser class with the PromptTemplate to ensure the results will be in a list format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c8185a8-7892-4e56-8115-f0e1058f04f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'synthetic, man-made, fake, simulated, imitation, faux, counterfeit, ersatz, fabricated, manufactured'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain import PromptTemplate, OpenAI, LLMChain\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "template = \"\"\"List all possible words as substitute for 'artificial' as comma separated.\"\"\"\n",
    "\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate(template=template, output_parser=output_parser, input_variables=[]),\n",
    "    )\n",
    "\n",
    "llm_chain.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ac5598-b34d-4543-9fb1-c7fa3e899c26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
