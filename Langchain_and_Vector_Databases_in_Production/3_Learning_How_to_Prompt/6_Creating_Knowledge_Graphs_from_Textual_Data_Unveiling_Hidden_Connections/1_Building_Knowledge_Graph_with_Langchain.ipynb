{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3a0c463b-865a-4c69-b4f8-3991c62b22af",
   "metadata": {},
   "source": [
    "'''\n",
    "Knowledge Graphs and Knowledge Bases: know the difference.\n",
    "Before diving deep into our main topic, it's important to have a clear understanding of the difference between Knowledge Graphs and Knowledge Bases.\n",
    "\n",
    "The terms \"knowledge graph\" and \"knowledge base\" are often used interchangeably, but they have subtle differences. Knowledge base (KB) refers to structured information that we have about a domain of interest. On the other hand, a knowledge graph is a knowledge base structured as a graph, where nodes represent entities and edges signify relations between those entities. For example, from the text “Fabio lives in Italy,” we can extract the relation triplet <Fabio, lives in, Italy>, where “Fabio” and “Italy” are entities, and “lives in” it’s their relation.\n",
    "\n",
    "A knowledge graph is a particular type of knowledge base. A knowledge base is not necessarily a knowledge graph."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e98fe390-0bc8-41da-831e-5f6bc687eca5",
   "metadata": {},
   "source": [
    "Building a Knowledge Graph\n",
    "The process of building a knowledge graph usually consists of two sequential steps:\n",
    "\n",
    "Named Entity Recognition (NER): This step involves extracting entities from the text, which will eventually become the nodes of the knowledge graph.\n",
    "Relation Classification (RC): In this step, relations between entities are extracted, forming the edges of the knowledge graph."
   ]
  },
  {
   "cell_type": "raw",
   "id": "1643faf8-cf56-4266-abfc-778a91aa3fda",
   "metadata": {},
   "source": [
    "Typically the process of creating a knowledge base from the text can be enhanced by incorporating additional steps, such as:\n",
    "\n",
    "Entity Linking: This involves normalizing entities to the same entity, such as “Napoleon” and “Napoleon Bonapart.” This is usually done by linking them to a canonical source, like a Wikipedia page.\n",
    "Source Tracking: Keeping track of the origin of each relation, such as the article URL and text span. Keeping track of the sources allows us to gather insights into the reliability of the extracted information (e.g., a relation is accurate if it can be extracted from several sources considered accurate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "744cf2ec-c91a-4f83-bd3d-67e56773c69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, dotenv_values\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "config = dotenv_values(\"C:/Users/SACHENDRA/Documents/Activeloop/.env\")\n",
    "load_dotenv(\"C:/Users/SACHENDRA/Documents/Activeloop/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "297c39a4-279a-4d96-8511-05646cad1dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SACHENDRA\\miniconda3\\envs\\activeloop2\\Lib\\site-packages\\langchain\\llms\\openai.py:165: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "C:\\Users\\SACHENDRA\\miniconda3\\envs\\activeloop2\\Lib\\site-packages\\langchain\\llms\\openai.py:677: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Paris, is the capital of, France)<|>(Paris, is the most populous city of, France)<|>(Eiffel Tower, is a famous landmark in, Paris)\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.graphs.networkx_graph import KG_TRIPLE_DELIMITER\n",
    "\n",
    "# Prompt template for knowledge triple extraction\n",
    "_DEFAULT_KNOWLEDGE_TRIPLE_EXTRACTION_TEMPLATE = (\n",
    "    \"You are a networked intelligence helping a human track knowledge triples\"\n",
    "    \" about all relevant people, things, concepts, etc. and integrating\"\n",
    "    \" them with your knowledge stored within your weights\"\n",
    "    \" as well as that stored in a knowledge graph.\"\n",
    "    \" Extract all of the knowledge triples from the text.\"\n",
    "    \" A knowledge triple is a clause that contains a subject, a predicate,\"\n",
    "    \" and an object. The subject is the entity being described,\"\n",
    "    \" the predicate is the property of the subject that is being\"\n",
    "    \" described, and the object is the value of the property.\\n\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"It's a state in the US. It's also the number 1 producer of gold in the US.\\n\\n\"\n",
    "    f\"Output: (Nevada, is a, state){KG_TRIPLE_DELIMITER}(Nevada, is in, US)\"\n",
    "    f\"{KG_TRIPLE_DELIMITER}(Nevada, is the number 1 producer of, gold)\\n\"\n",
    "    \"END OF EXAMPLE\\n\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"I'm going to the store.\\n\\n\"\n",
    "    \"Output: NONE\\n\"\n",
    "    \"END OF EXAMPLE\\n\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"Oh huh. I know Descartes likes to drive antique scooters and play the mandolin.\\n\"\n",
    "    f\"Output: (Descartes, likes to drive, antique scooters){KG_TRIPLE_DELIMITER}(Descartes, plays, mandolin)\\n\"\n",
    "    \"END OF EXAMPLE\\n\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"{text}\"\n",
    "    \"Output:\"\n",
    ")\n",
    "\n",
    "KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=_DEFAULT_KNOWLEDGE_TRIPLE_EXTRACTION_TEMPLATE,\n",
    ")\n",
    "\n",
    "# Make sure to save your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
    "# Instantiate the OpenAI model\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.9)\n",
    "\n",
    "# Create an LLMChain using the knowledge triple extraction prompt\n",
    "chain = LLMChain(llm=llm, prompt=KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT)\n",
    "\n",
    "# Run the chain with the specified text\n",
    "text = \"The city of Paris is the capital and most populous city of France. The Eiffel Tower is a famous landmark in Paris.\"\n",
    "triples = chain.run(text)\n",
    "\n",
    "print(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8852ec91-96b6-4ddf-af6c-ba72491d0cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(Paris, is the capital of, France)', '(Paris, is the most populous city of, France)', '(Eiffel Tower, is a famous landmark in, Paris)']\n"
     ]
    }
   ],
   "source": [
    "# Collecting triplets as a list\n",
    "def parse_triples(response, delimiter=KG_TRIPLE_DELIMITER):\n",
    "    if not response:\n",
    "        return []\n",
    "    return response.split(delimiter)\n",
    "\n",
    "triples_list = parse_triples(triples)\n",
    "\n",
    "# Print the extracted relation triplets\n",
    "print(triples_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db99e907-ba77-40af-b032-99761ad77da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyvis\n",
      "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: ipython>=5.3.0 in c:\\users\\sachendra\\miniconda3\\envs\\activeloop2\\lib\\site-packages (from pyvis) (8.22.2)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in c:\\users\\sachendra\\miniconda3\\envs\\activeloop2\\lib\\site-packages (from pyvis) (3.1.3)\n",
      "Collecting jsonpickle>=1.4.1 (from pyvis)\n",
      "  Downloading jsonpickle-3.0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting networkx>=1.11 (from pyvis)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: decorator in c:\\users\\sachendra\\miniconda3\\envs\\activeloop2\\lib\\site-packages (from ipython>=5.3.0->pyvis) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\sachendra\\miniconda3\\envs\\activeloop2\\lib\\site-packages (from ipython>=5.3.0->pyvis) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\sachendra\\miniconda3\\envs\\activeloop2\\lib\\site-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\sachendra\\miniconda3\\envs\\activeloop2\\lib\\site-packages (from ipython>=5.3.0->pyvis) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\sachendra\\miniconda3\\envs\\activeloop2\\lib\\site-packages (from ipython>=5.3.0->pyvis) (2.17.2)\n",
      "Requirement already satisfied: stack-data in c:\\users\\sachendra\\miniconda3\\envs\\activeloop2\\lib\\site-packages (from ipython>=5.3.0->pyvis) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\sachendra\\miniconda3\\envs\\activeloop2\\lib\\site-packages (from ipython>=5.3.0->pyvis) (5.14.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sachendra\\miniconda3\\envs\\activeloop2\\lib\\site-packages (from ipython>=5.3.0->pyvis) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sachendra\\miniconda3\\envs\\activeloop2\\lib\\site-packages (from jinja2>=2.9.6->pyvis) (2.1.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\sachendra\\miniconda3\\envs\\activeloop2\\lib\\site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\sachendra\\miniconda3\\envs\\activeloop2\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\sachendra\\miniconda3\\envs\\activeloop2\\lib\\site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\sachendra\\miniconda3\\envs\\activeloop2\\lib\\site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\sachendra\\miniconda3\\envs\\activeloop2\\lib\\site-packages (from stack-data->ipython>=5.3.0->pyvis) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sachendra\\miniconda3\\envs\\activeloop2\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=5.3.0->pyvis) (1.16.0)\n",
      "Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
      "   ---------------------------------------- 0.0/756.0 kB ? eta -:--:--\n",
      "   - ------------------------------------- 20.5/756.0 kB 330.3 kB/s eta 0:00:03\n",
      "   ---- ---------------------------------- 81.9/756.0 kB 919.0 kB/s eta 0:00:01\n",
      "   ------- -------------------------------- 143.4/756.0 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 194.6/756.0 kB 1.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 215.0/756.0 kB 1.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 215.0/756.0 kB 1.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 378.9/756.0 kB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 440.3/756.0 kB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 491.5/756.0 kB 1.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 522.2/756.0 kB 1.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 522.2/756.0 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 686.1/756.0 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  747.5/756.0 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 756.0/756.0 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading jsonpickle-3.0.4-py3-none-any.whl (39 kB)\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.7 MB 1.9 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.1/1.7 MB 1.6 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.1/1.7 MB 1.4 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.2/1.7 MB 1.5 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.3/1.7 MB 1.5 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.4/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.5/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.5/1.7 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.6/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.6/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.7/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.8/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.8/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.9/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.0/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.0/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.1/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.1/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.2/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.3/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.4/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.5/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.5/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.6/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: networkx, jsonpickle, pyvis\n",
      "Successfully installed jsonpickle-3.0.4 networkx-3.3 pyvis-0.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc903848-a576-48b5-8340-36862cfdf427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(Paris, is the capital of, France)', '(Paris, is the most populous city of, France)', '(Eiffel Tower, is a famous landmark in, Paris)']\n",
      "Edges in Graph: [('(Paris', 'France)', {'label': 'is the capital of'})]\n",
      "Edges in Graph: [('(Paris', 'France)', {'label': 'is the most populous city of'})]\n",
      "Edges in Graph: [('(Paris', 'France)', {'label': 'is the most populous city of'}), ('(Eiffel Tower', 'Paris)', {'label': 'is a famous landmark in'})]\n",
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "knowledge_graph.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"knowledge_graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2baa82e0b00>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Knowledge Graph Visualizations using pyvis library\n",
    "'''\n",
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "\n",
    "# Create a NetworkX graph from the extracted relation triplets\n",
    "def create_graph_from_triplets(triplets):\n",
    "    G = nx.DiGraph()\n",
    "    for triplet in triplets:\n",
    "        subject, predicate, obj = triplet.strip().split(',')\n",
    "        G.add_edge(subject.strip(), obj.strip(), label=predicate.strip())\n",
    "        print(\"Edges in Graph:\", G.edges(data=True))\n",
    "    return G\n",
    "    # for triplet in triplets:\n",
    "    #     # Remove leading and trailing spaces, and strip parentheses\n",
    "    #     subject, predicate, obj = [part.strip().strip('()') for part in triplet.split(',')]\n",
    "    #     print(subject, predicate, obj)\n",
    "\n",
    "    #     # Ensure proper handling of spaces in the predicate\n",
    "    #     predicate = predicate.replace(\"_\", \" \")  # Replacing underscores with spaces\n",
    "    #     print(\"Processed Predicate:\", predicate)\n",
    "\n",
    "    #     # Add the edge to the graph\n",
    "    #     G.add_edge(subject, obj, label=predicate)\n",
    "        \n",
    "    #     print(\"Edges in Graph:\", G.edges(data=True))\n",
    "    return G\n",
    "\n",
    "# Convert the NetworkX graph to a PyVis network\n",
    "def nx_to_pyvis(networkx_graph):\n",
    "    pyvis_graph = Network(notebook=True)\n",
    "    for node in networkx_graph.nodes():\n",
    "        pyvis_graph.add_node(node)\n",
    "    for edge in networkx_graph.edges(data=True):\n",
    "        pyvis_graph.add_edge(edge[0], edge[1], label=edge[2][\"label\"])\n",
    "    return pyvis_graph\n",
    "\n",
    "triplets = [t.strip() for t in triples_list if t.strip()]\n",
    "print(triplets)\n",
    "graph = create_graph_from_triplets(triplets)\n",
    "pyvis_network = nx_to_pyvis(graph)\n",
    "\n",
    "# Customize the appearance of the graph\n",
    "pyvis_network.toggle_hide_edges_on_drag(True)\n",
    "pyvis_network.toggle_physics(False)\n",
    "pyvis_network.set_edge_smooth('discrete')\n",
    "\n",
    "# Show the interactive knowledge graph visualization\n",
    "pyvis_network.show('knowledge_graph.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1376eb5-79bd-4ccc-81f6-e1bc139e15f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
