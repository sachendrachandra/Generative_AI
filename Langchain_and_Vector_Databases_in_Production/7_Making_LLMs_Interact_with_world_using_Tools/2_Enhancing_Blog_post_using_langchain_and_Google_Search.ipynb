{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b478555f-b3aa-4641-a581-e45d2c81ac02",
   "metadata": {},
   "source": [
    "Introduction:\n",
    "\n",
    "These days, artificial intelligence is changing the copywriting field by serving as a writing assistant. These language models can find spelling or grammatical errors, change tones, summarize, or even extend the content. However, there are times when the model may not have the specialized knowledge in a particular field to provide expert-level suggestions for extending parts of an article.\n",
    "\n",
    "In this lesson, we will take you step by step through the process of building an application that can effortlessly expand text sections. The process begins by asking an LLM (ChatGPT) to generate a few search queries based on the text at hand. These queries are then will be used to search the Internet using Google Search API that, captures relevant information on the subject. Lastly, the most relevant results will be presented as context to the model to suggest better content.\n",
    "\n",
    "We've got three variables here that hold an article's title and content (text_all). (From Artificial Intelligence News) Also, the text_to_change variable specifies which part of the text we want to expand upon. These constants are mentioned as a reference and will remain unchanged throughout the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72da4296-e273-4965-8a1e-fc5e3045ba2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, dotenv_values\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "config = dotenv_values(\"C:/Users/SACHENDRA/Documents/Activeloop/.env\")\n",
    "load_dotenv(\"C:/Users/SACHENDRA/Documents/Activeloop/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ae32ae8-21d1-4e3a-ad4a-ec6ec567c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"OpenAI CEO: AI regulation ‘is essential’\"\n",
    "\n",
    "text_all = \"\"\" Altman highlighted the potential benefits of AI technologies like ChatGPT and Dall-E 2 to help address significant challenges such as climate change and cancer, but he also stressed the need to mitigate the risks associated with increasingly powerful AI models.\n",
    "Altman proposed that governments consider implementing licensing and testing requirements for AI models that surpass a certain threshold of capabilities. He highlighted OpenAI’s commitment to safety and extensive testing before releasing any new systems, emphasising the company’s belief that ensuring the safety of AI is crucial.\n",
    "Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. \n",
    "Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology. Blumenthal raised concerns about various risks associated with AI, including deepfakes, weaponised disinformation, discrimination, harassment, and impersonation fraud. He also emphasised the potential displacement of workers in the face of a new industrial revolution driven by AI.\"\"\"\n",
    "\n",
    "text_to_change = \"\"\" Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security.\n",
    "Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7d5e058-d4bf-4e38-a0e1-722859de63f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q newspaper3k==0.2.8 python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8c772b0-93d9-49e0-b02c-83193e46f412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SACHENDRA\\miniconda3\\envs\\activeloop2\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\SACHENDRA\\miniconda3\\envs\\activeloop2\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\SACHENDRA\\miniconda3\\envs\\activeloop2\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AI voice cloning software technology advancements', 'Impact of AI on elections and security', 'Strategies to address risks associated with AI in job displacement']\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "template = \"\"\" You are an exceptional copywriter and content creator.\n",
    "\n",
    "You're reading an article with the following title:\n",
    "----------------\n",
    "{title}\n",
    "----------------\n",
    "\n",
    "You've just read the following piece of text from that article.\n",
    "----------------\n",
    "{text_all}\n",
    "----------------\n",
    "\n",
    "Inside that text, there's the following TEXT TO CONSIDER that you want to enrich with new details.\n",
    "----------------\n",
    "{text_to_change}\n",
    "----------------\n",
    "\n",
    "What are some simple and high-level Google queries that you'd do to search for more info to add to that paragraph?\n",
    "Write 3 queries as a bullet point list, prepending each line with -.\n",
    "\"\"\"\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"text_to_change\", \"text_all\", \"title\"],\n",
    "    )\n",
    ")\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "\n",
    "# Before executing the following code, make sure to have\n",
    "# your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.9)\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template)\n",
    "\n",
    "response = chain.run({\n",
    "    \"text_to_change\": text_to_change,\n",
    "    \"text_all\": text_all,\n",
    "    \"title\": title\n",
    "})\n",
    "\n",
    "queries = [line[2:] for line in response.split(\"\\n\")]\n",
    "print(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb911233-b9ec-45a6-a359-df64cfe7879a",
   "metadata": {},
   "source": [
    "The next step is to use the generated queries from the previous section to get a number of sources from Google searches. The LangChain library provides the GoogleSearchAPIWrapper utility that takes care of receiving search results and makes a function to run it top_n_results. Then, the Tool class will create a wrapper around the said function to make it compatible with agents and help them to interact with the outside world. We only ask for the top 5 results and concatenate the results for each query in the all_results variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "653e6a90-e00c-4347-95d5-4ec3f55a7572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SACHENDRA\\miniconda3\\envs\\activeloop2\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `GoogleSearchAPIWrapper` was deprecated in LangChain 0.0.33 and will be removed in 0.3.0. An updated version of the class exists in the langchain-google-community package and should be used instead. To use it run `pip install -U langchain-google-community` and import as `from langchain_google_community import GoogleSearchAPIWrapper`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "\n",
    "# Remember to set the \"GOOGLE_CSE_ID\" and \"GOOGLE_API_KEY\" environment variable.\n",
    "search = GoogleSearchAPIWrapper()\n",
    "TOP_N_RESULTS = 5\n",
    "\n",
    "def top_n_results(query):\n",
    "    return search.results(query, TOP_N_RESULTS)\n",
    "\n",
    "tool = Tool(\n",
    "    name = \"Google Search\",\n",
    "    description=\"Search Google for recent results.\",\n",
    "    func=top_n_results\n",
    ")\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for query in queries:\n",
    "    results = tool.run(query)\n",
    "    all_results += results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d8c4e9-cb6c-4168-a478-7275fe5d1f0a",
   "metadata": {},
   "source": [
    "Find the Most Relevant Results:\n",
    "\n",
    "As mentioned before, Google Search will return the URL for each source. However, we need the content of these pages. The newspaper package can extract the contents of a web link using the .parse() method. The following code will loop through the results and attempt to extract the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eed40c9b-bed2-447a-bca2-ddafad8ae9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages:  15\n"
     ]
    }
   ],
   "source": [
    "import newspaper\n",
    "\n",
    "pages_content = []\n",
    "\n",
    "for result in all_results:\n",
    "\ttry:\n",
    "\t\tarticle = newspaper.Article(result[\"link\"])\n",
    "\t\tarticle.download()\n",
    "\t\tarticle.parse()\n",
    "\n",
    "\t\tif len(article.text) > 0:\n",
    "\t\t\tpages_content.append({ \"url\": result[\"link\"], \"text\": article.text })\n",
    "\texcept:\n",
    "\t\tcontinue\n",
    "\n",
    "print(\"Number of pages: \", len(pages_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a49ef37-31b8-47fa-b1ea-714a58fbd465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks:  80\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=100)\n",
    "\n",
    "docs = []\n",
    "for d in pages_content:\n",
    "    chunks = text_splitter.split_text(d[\"text\"])\n",
    "    for chunk in chunks:\n",
    "        new_doc = Document(page_content=chunk, metadata={ \"source\": d[\"url\"] })\n",
    "        docs.append(new_doc)\n",
    "\n",
    "print(\"Number of chunks: \", len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03f9f67a-ba9a-47fa-b792-bdf551488e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SACHENDRA\\miniconda3\\envs\\activeloop2\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "docs_embeddings = embeddings.embed_documents([doc.page_content for doc in docs])\n",
    "query_embedding = embeddings.embed_query(text_to_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7040722c-4d98-4ccf-8c6b-ad5d64d952c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_top_k_indices(list_of_doc_vectors, query_vector, top_k):\n",
    "    # convert the lists of vectors to numpy arrays\n",
    "    list_of_doc_vectors = np.array(list_of_doc_vectors)\n",
    "    query_vector = np.array(query_vector)\n",
    "\n",
    "    # compute cosine similarities\n",
    "    similarities = cosine_similarity(query_vector.reshape(1, -1), list_of_doc_vectors).flatten()\n",
    "\n",
    "    # sort the vectors based on cosine similarity\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "\n",
    "    # retrieve the top K indices from the sorted list\n",
    "    top_k_indices = sorted_indices[:top_k]\n",
    "\n",
    "    return top_k_indices\n",
    "\n",
    "top_k = 3\n",
    "best_indexes = get_top_k_indices(docs_embeddings, query_embedding, top_k)\n",
    "best_k_documents = [doc for i, doc in enumerate(docs) if i in best_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea01de5-efb2-4ee3-bdeb-934b60ef5d26",
   "metadata": {},
   "source": [
    "Extend the Sentence:\n",
    "We can now define the prompt using the additional information from Google search. There are six input variables in the template:\n",
    "\n",
    "1. title that holds the main article’s title;\n",
    "2. text_all to present the whole article we are working on;\n",
    "3. text_to_change is the selected part of the article that requires expansion;\n",
    "4. doc_1, doc_2, doc_3 to include the close Google search results as context.\n",
    "The remaining part of the code should be familiar, as it follows the same structure used for generating Google queries. It defines a HumanMessage template to be compatible with the ChatGPT API, which is defined with a high-temperature value to encourage creativity. The LLMChain class will create a chain that combines the model and prompt to finish up the process by using .run() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e97c012c-6f02-4b85-9419-af0f6f86b0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to Change:   Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security.\n",
      "Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology.\n",
      "Expanded Variation: Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology. This move comes in the midst of a new era in elections where AI tools allow for the synthesis of audio in anyone's voice, generating photo-realistic images, and powering social media bot accounts with near-human conversational abilities. The use of generative AI in elections has raised concerns about disinformation, deliberate mischief, and potential voter suppression. Blumenthal's demonstration highlights the growing risks associated with AI in elections, including the spread of deepfake content, misinformation campaigns, and the need for enhanced detection and anti-phishing tools to safeguard the electoral process. In light of these challenges, there is a call for governmental, civil society, and private sector action to protect elections from the threats posed by AI technologies.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"You are an exceptional copywriter and content creator.\n",
    "\n",
    "You're reading an article with the following title:\n",
    "----------------\n",
    "{title}\n",
    "----------------\n",
    "\n",
    "You've just read the following piece of text from that article.\n",
    "----------------\n",
    "{text_all}\n",
    "----------------\n",
    "\n",
    "Inside that text, there's the following TEXT TO CONSIDER that you want to enrich with new details.\n",
    "----------------\n",
    "{text_to_change}\n",
    "----------------\n",
    "\n",
    "Searching around the web, you've found this ADDITIONAL INFORMATION from distinct articles.\n",
    "----------------\n",
    "{doc_1}\n",
    "----------------\n",
    "{doc_2}\n",
    "----------------\n",
    "{doc_3}\n",
    "----------------\n",
    "\n",
    "Modify the previous TEXT TO CONSIDER by enriching it with information from the previous ADDITIONAL INFORMATION.\n",
    "\"\"\"\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"text_to_change\", \"text_all\", \"title\", \"doc_1\", \"doc_2\", \"doc_3\"],\n",
    "    )\n",
    ")\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.9)\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template)\n",
    "\n",
    "response = chain.run({\n",
    "    \"text_to_change\": text_to_change,\n",
    "    \"text_all\": text_all,\n",
    "    \"title\": title,\n",
    "    \"doc_1\": best_k_documents[0].page_content,\n",
    "    \"doc_2\": best_k_documents[1].page_content,\n",
    "    \"doc_3\": best_k_documents[2].page_content\n",
    "})\n",
    "\n",
    "print(\"Text to Change: \", text_to_change)\n",
    "print(\"Expanded Variation:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ad4512-77f1-4ede-8faa-5514f3570fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
