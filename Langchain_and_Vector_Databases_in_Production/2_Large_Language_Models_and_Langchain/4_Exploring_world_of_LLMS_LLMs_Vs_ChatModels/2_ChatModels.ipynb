{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe122f0f-1702-4b58-ab4d-5b4a996cc95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, dotenv_values\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "config = dotenv_values(\"C:/Users/SACHENDRA/Documents/Activeloop/.env\")\n",
    "load_dotenv(\"C:/Users/SACHENDRA/Documents/Activeloop/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ec6887b-94a6-4f35-b921-4e5efe87b77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SACHENDRA\\miniconda3\\envs\\activeloop2\\Lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (3.9.1) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'aime la programmation.\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "  HumanMessage,\n",
    "  SystemMessage\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "\n",
    "messages = [\n",
    "\tSystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "\tHumanMessage(content=\"Translate the following sentence: I love programming.\")\n",
    "]\n",
    "\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "608208ca-e0dd-4441-bf93-fa84d6bbc146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[ChatGeneration(text=\"J'aime la programmation.\", generation_info=None, message=AIMessage(content=\"J'aime la programmation.\", additional_kwargs={}, example=False))], [ChatGeneration(text='I love programming.', generation_info=None, message=AIMessage(content='I love programming.', additional_kwargs={}, example=False))]] llm_output={'token_usage': {'prompt_tokens': 65, 'completion_tokens': 11, 'total_tokens': 76}, 'model_name': 'gpt-4'} run=RunInfo(run_id=UUID('e1ffdabb-385e-4349-bdb9-ab6ed09afb3c'))\n"
     ]
    }
   ],
   "source": [
    "batch_messages = [\n",
    "  [\n",
    "    SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "    HumanMessage(content=\"Translate the following sentence: I love programming.\")\n",
    "  ],\n",
    "  [\n",
    "    SystemMessage(content=\"You are a helpful assistant that translates French to English.\"),\n",
    "    HumanMessage(content=\"Translate the following sentence: J'aime la programmation.\")\n",
    "  ],\n",
    "]\n",
    "print( chat.generate(batch_messages) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee75888-598f-4266-8812-c56d7f5e132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "LLMs and Chat Models each have their advantages and disadvantages.\n",
    "LLMs are powerful and flexible, capable of generating text for a wide range of tasks.\n",
    "However, their API is less structured compared to Chat Models.\n",
    "\n",
    "On the other hand, Chat Models offer a more structured API and are better suited for conversational tasks.\n",
    "Also, they can remember previous exchanges with the user, making them more suitable for engaging in meaningful conversations.\n",
    "Additionally, they benefit from reinforcement learning from human feedback, which helps improve their responses.\n",
    "They still have some limitations in reasoning and may require careful handling to avoid hallucinations and generating inappropriate content.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
